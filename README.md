# News_Classification-lab
This repository has the objetive to train and compare transformer-based models (RoBERTa, DeBERTa, ModernBERT) on the AG News dataset. through a .py from Google Collab.

# Task 2: Transformer Models for News Classification (AG News)

## Descripción del Proyecto:

Este proyecto implementa y compara estos tres modelos transformer de última generación para la clasificación de noticias:

1. **RoBERTa-base** - Modelo optimizado de BERT
2. **DeBERTa-v3-base** - Modelo con atención desacoplada
3. **ModernBERT (BERT-base-uncased)** - Arquitectura BERT clásica

## Objetivos

- Fine-tuning de modelos transformer para clasificación multiclase
- Evaluación rigurosa con splits 70/15/15 (train/val/test)
- Comparación de rendimiento usando F1-score
- **Bonus**: Clasificación con LLM y análisis comparativo

